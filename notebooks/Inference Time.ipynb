{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "src_short = \"Please exit the plane after landing.\"\n",
    "tgt_short = \"Bitte verlassen Sie das Flugzeug.\"\n",
    "src_long = \"This is a very long source sentence and if a neural machine translation system translates it into German it is possible that some words or even combinations of words will be missed in the translation.\"\n",
    "tgt_long = \"Dies ist ein sehr langer Ausgangssatz, und wenn ein neuronales maschinelles Übersetzungssystem ihn ins Deutsche übersetzt, ist es möglich aber nicht wahrscheinlich, dass einige Wörter oder sogar Wortkombinationen in der Übersetzung fehlen.\"\n",
    "\n",
    "num_repetitions = 1000"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Our approach"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Load model\n",
    "from coverage.evaluator import CoverageEvaluator\n",
    "from translation_models import load_forward_and_backward_model\n",
    "\n",
    "forward_model, backward_model = load_forward_and_backward_model(\"mbart50\", src_lang=\"en\", tgt_lang=\"de\")\n",
    "\n",
    "evaluator = CoverageEvaluator(\n",
    "  src_lang=\"en\",\n",
    "  tgt_lang=\"de\",\n",
    "  forward_evaluator=forward_model,\n",
    "  backward_evaluator=backward_model,\n",
    "  batch_size=16,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Additions only"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39.73716928437352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lib/python3.7/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164.98447458446026\n",
      "18.294793820008636\n",
      "101.81147654913366\n"
     ]
    }
   ],
   "source": [
    "evaluator.forward_evaluator = None\n",
    "\n",
    "# Including parser\n",
    "for src, tgt in [\n",
    "    (src_short, tgt_short),\n",
    "    (src_long, tgt_long),\n",
    "]:\n",
    "    print(timeit.timeit(lambda: evaluator.detect_errors(\n",
    "        src=src,\n",
    "        translation=tgt,\n",
    "    ), number=num_repetitions))\n",
    "\n",
    "# Excluding parser\n",
    "for src, tgt in [\n",
    "    (src_short, tgt_short),\n",
    "    (src_long, tgt_long),\n",
    "]:\n",
    "    src_doc = evaluator.src_parser(src)\n",
    "    tgt_doc = evaluator.tgt_parser(tgt)\n",
    "    print(timeit.timeit(lambda: evaluator.detect_errors(\n",
    "        src=src,\n",
    "        translation=tgt,\n",
    "        src_doc=src_doc,\n",
    "        translation_doc=tgt_doc,\n",
    "    ), number=num_repetitions))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Omissions only"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.974007941782475\n",
      "197.40284639038146\n",
      "20.97033300064504\n",
      "143.96992459148169\n"
     ]
    }
   ],
   "source": [
    "evaluator.forward_evaluator = forward_model\n",
    "evaluator.backward_evaluator = None\n",
    "\n",
    "# Including parser\n",
    "for src, tgt in [\n",
    "    (src_short, tgt_short),\n",
    "    (src_long, tgt_long),\n",
    "]:\n",
    "    print(timeit.timeit(lambda: evaluator.detect_errors(\n",
    "        src=src,\n",
    "        translation=tgt,\n",
    "    ), number=num_repetitions))\n",
    "\n",
    "# Excluding parser\n",
    "for src, tgt in [\n",
    "    (src_short, tgt_short),\n",
    "    (src_long, tgt_long),\n",
    "]:\n",
    "    src_doc = evaluator.src_parser(src)\n",
    "    tgt_doc = evaluator.tgt_parser(tgt)\n",
    "    print(timeit.timeit(lambda: evaluator.detect_errors(\n",
    "        src=src,\n",
    "        translation=tgt,\n",
    "        src_doc=src_doc,\n",
    "        translation_doc=tgt_doc,\n",
    "    ), number=num_repetitions))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Both error types"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82.75419463589787\n",
      "365.30587567947805\n",
      "37.87803195416927\n",
      "238.93906163983047\n"
     ]
    }
   ],
   "source": [
    "evaluator.forward_evaluator = forward_model\n",
    "evaluator.backward_evaluator = backward_model\n",
    "\n",
    "# Including parser\n",
    "for src, tgt in [\n",
    "    (src_short, tgt_short),\n",
    "    (src_long, tgt_long),\n",
    "]:\n",
    "    print(timeit.timeit(lambda: evaluator.detect_errors(\n",
    "        src=src,\n",
    "        translation=tgt,\n",
    "    ), number=num_repetitions))\n",
    "\n",
    "# Excluding parser\n",
    "for src, tgt in [\n",
    "    (src_short, tgt_short),\n",
    "    (src_long, tgt_long),\n",
    "]:\n",
    "    src_doc = evaluator.src_parser(src)\n",
    "    tgt_doc = evaluator.tgt_parser(tgt)\n",
    "    print(timeit.timeit(lambda: evaluator.detect_errors(\n",
    "        src=src,\n",
    "        translation=tgt,\n",
    "        src_doc=src_doc,\n",
    "        translation_doc=tgt_doc,\n",
    "    ), number=num_repetitions))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Baseline"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vocabulary for source already exists; not loading it again\n",
      "Vocabulary for target already exists; not loading it again\n",
      "Vocabulary for pe already exists; not loading it again\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "from kiwi.lib.predict import load_system\n",
    "runner = load_system(Path(\".\") / \"runs/0/newscrawl.en-de.partial.100k.large.seed1/checkpoints/model_epoch=05-val_source_tags_F1_MULT+target_tags_F1_MULT=1.88.ckpt\", gpu_id=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.569993468001485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.414803167805076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Measure inference time\n",
    "for src, tgt in [\n",
    "    (src_short, tgt_short),\n",
    "    (src_long, tgt_long),\n",
    "]:\n",
    "    print(timeit.timeit(lambda: runner.predict(\n",
    "        source=[src],\n",
    "        target=[tgt],\n",
    "    ), number=num_repetitions))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Translating"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local/scratch/vamvas/envs/coveragetest/lib/python3.7/site-packages/transformers/pipelines/base.py:999: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  UserWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "253.98270384594798\n",
      "861.1719417851418\n"
     ]
    }
   ],
   "source": [
    "for src, _ in [\n",
    "    (src_short, tgt_short),\n",
    "    (src_long, tgt_long),\n",
    "]:\n",
    "    print(timeit.timeit(lambda: forward_model.translate(\n",
    "        src_lang=\"en\",\n",
    "        tgt_lang=\"de\",\n",
    "        sentences=[src],\n",
    "        beam=5,\n",
    "    ), number=num_repetitions))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "coveragetest",
   "language": "python",
   "display_name": "coveragetest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}